# main.py  -- Context Agent "V61 - " 
# Dependencies: discord.py, aiohttp, google-generativeai, python-dotenv, matplotlib, cachetools
# pip install -U discord.py aiohttp google-generativeai python-dotenv matplotlib cachetools

import os
import time
import asyncio
import re
import random
import logging
import io 
import json
import matplotlib.pyplot as plt 
from typing import Optional

import aiohttp
import discord
import google.generativeai as genai
from cachetools import TTLCache 

from dotenv import load_dotenv

# ------------------------
# Load config
# ------------------------
load_dotenv()
DISCORD_TOKEN = os.getenv("DISCORD_TOKEN")
MEMBIT_KEY = os.getenv("MEMBIT_API_KEY")
GEMINI_KEY = os.getenv("GEMINI_API_KEY")

CLUSTER_SEARCH_URL = "https://api.membit.ai/v1/clusters/search"
POST_SEARCH_URL = "https://api.membit.ai/v1/posts/search"
MEMBIT_HEADERS = {"X-Membit-Api-Key": MEMBIT_KEY, "User-Agent": "MembitContextAgent/77-Clean"}

COOLDOWN_SECONDS = int(os.getenv("COOLDOWN_SECONDS", "12"))
user_last_call = {}

COMMANDS_WITH_COOLDOWN = {"!hunt", "!analyze", "!trend", "!whatis", "!context", "!compare", "!risk", "!explain", "!graph"}

HACKATHON_FOOTER = "Insight generated by Membit Cluster Engine x Gemini AI"

# ------------------------
# Logging
# ------------------------
logging.basicConfig(level=logging.INFO, format="%(asctime)s %(levelname)s %(message)s")
logger = logging.getLogger("membit-agent-v61")

# ------------------------
# Gemini setup
# ------------------------
if GEMINI_KEY:
    genai.configure(api_key=GEMINI_KEY)

PREFERRED_MODELS = [
    "gemini-flash-latest",
    "gemini-pro-latest",
]

MODEL_NAME = None
model = None

def pick_available_model() -> str:
    try:
        available_models = [m.name for m in genai.list_models() if 'generateContent' in getattr(m, "supported_generation_methods", [])]
        for m_pref in PREFERRED_MODELS:
            if m_pref in available_models or f"models/{m_pref}" in available_models:
                logger.info(f"--- Memilih Model: {m_pref} ---")
                return m_pref
    except Exception as e:
        logger.warning(f"Warning: Gagal list model, pakai default. Error: {e}")
        return PREFERRED_MODELS[0]
    logger.warning("Warning: Model pilihan tidak ada, pakai default.")
    return PREFERRED_MODELS[0]

if GEMINI_KEY:
    MODEL_NAME = pick_available_model()
    try:
        model = genai.GenerativeModel(MODEL_NAME)
    except Exception as e:
        logger.error(f"FATAL: Could not initialize Gemini model '{MODEL_NAME}'. Error: {e}")
        model = None
else:
    logger.warning("GEMINI_KEY not set ‚Äî AI features will be disabled.")

# ------------------------
# Helpers for Gemini calls (SAFE-F MODE)
# ------------------------
async def call_gemini_safe(prompt: str, max_tokens: int = 180):
    """Versi ultra-ringan, aman untuk Gemini gratisan."""
    if not model:
        return None, "AI Model not initialized."

    try:
        gen_config = genai.types.GenerationConfig(
            max_output_tokens=max_tokens,
            temperature=0.4,
            top_p=0.8,
        )

        try:
            resp = await model.generate_content_async(prompt, generation_config=gen_config)
        except AttributeError:
            resp = await asyncio.to_thread(model.generate_content, prompt, generation_config=gen_config)

        pf = getattr(resp, "prompt_feedback", None)
        if pf and getattr(pf, "block_reason", None):
            logger.warning(f"Gemini prompt blocked: {pf.block_reason}")
            return None, f"Prompt Blocked ({pf.block_reason})"
        candidates = getattr(resp, "candidates", None)
        if not candidates:
            return None, "No candidates (likely blocked)."
        candidate = candidates[0]
        if getattr(candidate, "finish_reason", "") == 'SAFETY':
            return None, "Safety Block"
        parts = getattr(candidate, "content", None)
        if not parts or not getattr(parts, "parts", None):
            logger.warning(f"Gemini returned empty parts. Finish reason: {getattr(candidate, 'finish_reason', 'N/A')}")
            return None, "empty"
        txt = "".join(getattr(p, "text", "") for p in parts.parts).strip()
        
        if txt:
            return txt, ""
        else:
            return None, "empty"

    except Exception as e:
        logger.error(f"Exception calling Gemini (SAFE-F): {e}")
        return None, str(e)

async def call_gemini_short(prompt: str, max_tokens: int = 400):
    """Versi standar (non-safe) untuk !analyze"""
    if not model:
        return "‚ö†Ô∏è AI Model not initialized.", "AI Model not initialized."
    try:
        gen_config = genai.types.GenerationConfig(max_output_tokens=max_tokens)
        try:
            resp = await model.generate_content_async(prompt, generation_config=gen_config)
        except AttributeError:
            resp = await asyncio.to_thread(model.generate_content, prompt, generation_config=gen_config)
        pf = getattr(resp, "prompt_feedback", None)
        if pf and getattr(pf, "block_reason", None):
            return f"‚ö†Ô∏è AI Error: Prompt Blocked ({pf.block_reason})", str(pf.block_reason)
        candidates = getattr(resp, "candidates", None)
        if not candidates:
            return "‚ö†Ô∏è AI Error: No response generated (likely blocked).", "No candidates."
        candidate = candidates[0]
        if getattr(candidate, "finish_reason", "") == 'SAFETY':
            return "‚ö†Ô∏è AI Error: Response was blocked for safety reasons.", "SAFETY_BLOCK"
        text_response = ""
        parts = getattr(candidate, "content", None)
        if parts and getattr(parts, "parts", None):
            text_response = "".join(getattr(p, "text", "") for p in parts.parts).strip()
        if not text_response:
            logger.debug(f"DEBUG: Empty parts. Finish reason: {getattr(candidate, 'finish_reason', 'N/A')}")
            return None, "empty" 
        if getattr(candidate, "finish_reason", "") == 'MAX_TOKENS':
            text_response += "\n\n‚ö†Ô∏è (AI response was cut short...)"
        if text_response:
            return text_response, ""
    except Exception as e:
        logger.exception("Exception calling Gemini")
        return f"‚ö†Ô∏è AI Error: {e}", str(e)

# ------------------------
# Small utilities
# ------------------------
def now_ts():
    return int(time.time())
def within_cooldown(user_id):
    last = user_last_call.get(user_id, 0)
    return now_ts() - last < COOLDOWN_SECONDS
def set_cooldown(user_id):
    user_last_call[user_id] = now_ts()

RISK_KEYWORDS = {
    'scam': 40, 'hack': 40, 'exploit': 40, 'phish': 35, 'warning': 25, 'fraud': 35,
    'airdrop': -10, 'partnership': -7, 'reward': -8, 'upgrade': -6,
}
def compute_risk_score(text: str) -> int:
    t = (text or "").lower()
    score = 0
    for k, w in RISK_KEYWORDS.items():
        if k in t:
            score += w
    return max(0, min(100, score + 50))
def compute_color_from_score(score: int) -> int:
    if score >= 70: return 0xFF0000
    if score >= 40: return 0xFFD000
    return 0x00FF00
def get_recommendation_from_score(score: int) -> str:
    if score >= 70: return "üõë High-risk indicators detected. Verify legitimacy before interacting."
    if score >= 40: return "‚ö†Ô∏è Medium risk. Mixed signals ‚Äî review carefully."
    return "‚úÖ Low/neutral risk indicators. Looks generally safe."

def clean_text_summary(text: str) -> str:
    if not text: return ""
    text = re.sub(r'!\[[^\]]*\]\([^\)]+\)', '', text)
    text = re.sub(r'!image\s+https?://[^\s]+', '', text)
    text = re.sub(r'\[image\]', '', text)
    text = re.sub(r'https?://(?!x\.com|twitter\.com)[^\s]+', '', text)
    text = re.sub(r'\n{3,}', '\n\n', text)
    return text.strip()
def clean_text_post(text: str) -> str:
    if not text: return ""
    text = re.sub(r'!\[[^\]]*\]\([^\)]+\)', '', text)
    text = re.sub(r'!image\s+https?://[^\s]+', '', text)
    text = re.sub(r'\[image\]', '', text)
    text = re.sub(r'https?://[^\s]+', '', text)
    text = re.sub(r'\n{3,}', '\n\n', text)
    return text.strip()

def truncate(text, n=800):
    if not text: return ""
    return text if len(text) <= n else text[:n-1] + "‚Ä¶"

# ------------------------
# Async HTTP helper
# ------------------------
cluster_cache = TTLCache(maxsize=256, ttl=10) 

class SafeHTTP:
    def __init__(self):
        self.session: Optional[aiohttp.ClientSession] = None
    async def ensure(self):
        if self.session is None or self.session.closed:
            self.session = aiohttp.ClientSession(headers={"User-Agent": "MembitContextAgent/77-AIOHTTP"})
    async def close(self):
        if self.session and not self.session.closed:
            await self.session.close()
    async def get_json(self, url, headers=None, params=None, timeout=8, retries=2):
        await self.ensure()
        last_exc = None
        for attempt in range(retries+1):
            try:
                async with self.session.get(url, headers=headers, params=params, timeout=timeout) as resp:
                    text = await resp.text()
                    if resp.status != 200:
                        logger.warning(f"[DEBUG] Membit API returned {resp.status}: {text}")
                        last_exc = Exception(f"HTTP {resp.status}")
                        await asyncio.sleep(0.25 * (attempt+1))
                        continue
                    return await resp.json()
            except Exception as e:
                last_exc = e
                logger.debug(f"Attempt {attempt+1} failed for {url}: {e}")
                await asyncio.sleep(0.25 * (attempt+1))
        logger.error(f"safe_get failed after retries: {last_exc}")
        return None

safe_http = SafeHTTP()

def generate_heuristic_insight(clusters: list) -> dict:
    if not clusters:
        return {
            "summary": "No cluster data provided.",
            "recommendation": "Neutral signals.",
            "color": 0x00FF00,
            "score": 50
        }
    combined_text = " ".join([f"{c.get('label','')}: {c.get('summary','')}" for c in clusters])
    score = compute_risk_score(combined_text)
    color_hex = compute_color_from_score(score)
    rec = get_recommendation_from_score(score)
    keywords_found = []
    for k in RISK_KEYWORDS.keys():
        if k in combined_text.lower():
            keywords_found.append(k)
    summary = f"Summary ({len(clusters)} clusters): " + ", ".join([f"{c.get('label','N/A')}" for c in clusters[:5]])
    highlights = f"Keywords: {', '.join(keywords_found[:6])}" if keywords_found else "No immediate signal keywords found."
    return {
        "summary": summary + " ‚Äî " + highlights,
        "recommendation": rec,
        "color": color_hex,
        "score": score
    }

# ------------------------
# Discord client
# ------------------------
intents = discord.Intents.default()
intents.message_content = True
client = discord.Client(intents=intents)

@client.event
async def on_ready():
    logger.info(f"Bot ready ‚Äî model: {MODEL_NAME} | Version: V77 (Clean Build)")
    client.safe_http = safe_http 
    await client.change_presence(activity=discord.Activity(type=discord.ActivityType.watching, name="Membit Context ‚Ä¢ !help"))

# ------------------------
# Command handlers
# ------------------------
async def handle_help(channel):
    embed = discord.Embed(title="Membit Context Agent ‚Äî Help (V77)", color=0x0099FF)
    embed.add_field(name="!hunt <keyword>", value="Search Membit clusters (Heuristic Insight)", inline=False)
    embed.add_field(name="!analyze <text>", value="Ask AI for sentiment analysis (Safe Mode)", inline=False)
    embed.add_field(name="!risk <text>", value="Local (Weighted) risk analysis (V2)", inline=False)
    embed.add_field(name="!explain <term>", value="Simple AI definition (SAFE-F Mode)", inline=False)
    embed.add_field(name="!trend <keyword>", value="Quick trend summary (Data Only)", inline=False)
    embed.add_field(name="!context <topic>", value="Full Pipeline Analysis (SAFE-F Mode)", inline=False)
    embed.add_field(name="!graph <topic>", value="Show Engagement Graph (Membit Data)", inline=False)
    embed.add_field(name="!compare", value="[Coming Soon] Compare two topics", inline=False)
    embed.add_field(name="!whatis", value="[DEPRECATED] Use `!explain`", inline=False)
    embed.set_footer(text=HACKATHON_FOOTER)
    await channel.send(embed=embed)

async def handle_whatis(channel, author, term):
    await handle_explain(channel, term)

async def handle_analyze(channel, author, text):
    prompt = f"Analyze the sentiment of this text. Is it positive, negative, or neutral? Explain your reasoning briefly.\n\nText:\n{text}"
    await channel.send("üß† Asking AI for sentiment (Safe Mode)...")
    txt, err = await call_gemini_safe(prompt, max_tokens=300) 
    
    if err == "empty" or txt is None:
        txt = "üß† AI Fallback: The AI could not determine a sentiment. The text might be too neutral or complex."
        err = ""
    if err:
        await channel.send(f"‚ö†Ô∏è AI Error: {err}")
        return
        
    embed = discord.Embed(title="AI Sentiment Analysis", description=truncate(txt, 1500), color=0x00CC99)
    embed.set_footer(text="SAFE-F Mode ‚Äî AI Minimal, Heuristic Priority")
    await channel.send(embed=embed)

async def fetch_clusters(keyword: str, limit: int = 6):
    key = f"clusters:{keyword}:{limit}"
    if key in cluster_cache:
        logger.debug("Using cached cluster response")
        return cluster_cache[key]
    params = {"q": keyword, "limit": limit}
    data = await safe_http.get_json(CLUSTER_SEARCH_URL, headers=MEMBIT_HEADERS, params=params)
    if not data:
        return None
    clusters = data.get("clusters", [])[:limit]
    seen = set()
    unique = []
    for c in clusters:
        label = c.get('label', '').strip()
        if label.lower() in seen:
            continue
        seen.add(label.lower())
        unique.append(c)
    cluster_cache[key] = unique
    return unique

async def handle_hunt(channel, author, keyword, short_mode=False):
    await channel.send(f"üîé Hunting Membit for {keyword} ...")
    clusters = await fetch_clusters(keyword, limit=6)
    if clusters is None:
        await channel.send("‚ö†Ô∏è Membit API error or network issue.")
        return
    if not clusters:
        await channel.send("‚ùå No clusters found.")
        return
    insight = generate_heuristic_insight(clusters)
    batches = [clusters[i:i+3] for i in range(0, len(clusters), 3)]
    for idx, batch in enumerate(batches):
        embed = discord.Embed(
            title=f"Deep Hunt: {keyword} (page {idx+1}/{len(batches)})",
            description=f"{insight['recommendation']}\nShowing {len(batch)} clusters.",
            color=insight['color']
        )
        if idx == 0: 
            embed.add_field(
                name="Overall Insight (Heuristic)",
                value=f"_{truncate(insight['summary'], 900)}_",
                inline=False
            )
            embed.add_field(name="--- Cluster Data ---", value="\u200b", inline=False)
        for c in batch:
            label = c.get("label", "No label")
            summary = clean_text_summary(c.get("summary", "No summary"))
            field_value = f"{truncate(summary, 800)}"
            embed.add_field(name=f"{label}", value=field_value, inline=False)
        if short_mode:
            embed.set_author(name="LITE MODE ‚Ä¢ Short results")
        embed.set_footer(text=HACKATHON_FOOTER)
        await channel.send(embed=embed)
        await asyncio.sleep(0.6)

async def handle_trend(channel, keyword):
    await channel.send(f"üìà Gathering trend for {keyword} ...")
    clusters = await fetch_clusters(keyword, limit=8)
    if clusters is None:
        await channel.send("‚ö†Ô∏è Membit API error or network issue.")
        return
    if not clusters:
        await channel.send("‚ùå No recent clusters found.")
        return
    pos = neg = 0
    for c in clusters:
        score = compute_risk_score(c.get("summary","") or "")
        if score >= 70:
            neg += 1
        elif score <= 30:
            pos += 1
    embed = discord.Embed(title=f"Trend quick-scan: {keyword}", color=0x8AB4FF)
    embed.add_field(name="Sample size", value=str(len(clusters)), inline=True)
    embed.add_field(name="Positive signals", value=str(pos), inline=True)
    embed.add_field(name="Risk indicators", value=str(neg), inline=True)
    embed.set_footer(text=HACKATHON_FOOTER)
    await channel.send(embed=embed)

async def handle_context(channel, author, keyword):
    """Versi F ‚Äî Full Pipeline Aman (AI seminimal mungkin)."""
    await channel.send(f"üåê SAFE Context Analysis for **{keyword}** ...")

    local_risk_score = compute_risk_score(keyword)
    local_color = compute_color_from_score(local_risk_score)
    risk_rec = get_recommendation_from_score(local_risk_score)

    data = await safe_http.get_json(CLUSTER_SEARCH_URL, headers=MEMBIT_HEADERS, params={"q": keyword, "limit": 6})
    if not data or not data.get("clusters"):
        await channel.send("‚ö†Ô∏è Membit API error / no data.")
        return

    clusters = data["clusters"]
    heuristic = generate_heuristic_insight(clusters)

    ai_insight = None
    if model:
        clusters_summary = " ".join([truncate(c.get("summary",""), 120) for c in clusters])
        prompt = (
            "Give a short insight based on this context. "
            "Keep it under 4 sentences.\n\n"
            f"Context: {clusters_summary}"
        )
        ai_insight, _ = await call_gemini_safe(prompt)

    if not ai_insight:
        ai_insight = "AI disabled or quota reached ‚Äî Heuristic mode active."

    embed = discord.Embed(
        title=f"SAFE Context Report ‚Äî {keyword}",
        description=f"Query Risk Score: {local_risk_score}/100",
        color=local_color
    )
    embed.add_field(name="Risk (Local)", value=risk_rec, inline=False)
    embed.add_field(name="Data Insight (Heuristic)", value=truncate(heuristic["summary"], 600), inline=False)
    embed.add_field(name="AI (Safe Mode)", value=truncate(ai_insight, 800), inline=False)
    embed.set_footer(text="SAFE-F Mode ‚Äî AI Minimal, Heuristic Priority")
    await channel.send(embed=embed)

async def handle_risk(channel, author, text):
    await channel.send("üî¨ Scanning for risks (Weighted Engine V2)...")
    score = compute_risk_score(text)
    color_hex = compute_color_from_score(score)
    recommendation = get_recommendation_from_score(score)
    embed = discord.Embed(title="Risk Analysis (Engine V2)", description=recommendation, color=color_hex)
    embed.add_field(name="Risk Score", value=f"**{score}/100**", inline=True)
    embed.add_field(name="Input Text", value=truncate(text, 1000), inline=False)
    embed.set_footer(text="Weighted Risk Engine V2 ‚Äî Keyword Scoring Model")
    await channel.send(embed=embed)

def generate_graph_sync(labels, values, keyword):
    """Generates the graph in a sync function, returns a buffer."""
    try:
        buffer = io.BytesIO()
        plt.figure(figsize=(8,4)) 
        plt.plot(list(reversed(labels)), list(reversed(values)), marker="o", linestyle="--")
        plt.title(f"Engagement Trend ‚Äî {keyword}")
        plt.xlabel("Clusters (Oldest to Newest)")
        plt.ylabel("Engagement Score")
        plt.xticks(rotation=15, ha='right', fontsize=8) 
        plt.tight_layout()
        
        plt.savefig(buffer, format="png")
        buffer.seek(0)
        plt.close()
        return buffer, None # Sukses
    except Exception as e:
        logger.exception(f"Matplotlib error: {e}")
        return None, str(e) # Gagal

async def handle_graph(channel, author, keyword):
    await channel.send(f"üìä Building PNG Engagement Graph for **{keyword}** ...")
    data = await safe_http.get_json(CLUSTER_SEARCH_URL, headers=MEMBIT_HEADERS, params={"q": keyword, "limit": 8})
    if not data or "clusters" not in data:
        await channel.send("‚ö†Ô∏è Membit API error or no clusters found.")
        return
    clusters = data.get("clusters", [])
    if not clusters:
        await channel.send("‚ö†Ô∏è No cluster data found to plot.")
        return

    labels = []
    values = []
    for c in clusters:
        labels.append(c.get("label", "cluster"))
        val = c.get("engagement_score") or 0 
        try:
            values.append(float(val))
        except:
            values.append(0)
    if not values:
        await channel.send("‚ö†Ô∏è No numeric data found to plot.")
        return

    buffer, err = await asyncio.to_thread(generate_graph_sync, labels, values, keyword)
    
    if err:
        await channel.send(f"‚ö†Ô∏è Graphing error: {err}")
        return

    file = discord.File(fp=buffer, filename="trend.png")
    embed = discord.Embed(
        title=f"Engagement Graph ‚Äî {keyword}",
        description="Generated using Membit cluster engagement scores.",
        color=0x3BA3FF
    )
    embed.set_image(url="attachment://trend.png")
    embed.set_footer(text="Mode E+ ‚Äî Pure Python Graph (No AI)")
    await channel.send(file=file, embed=embed)

async def handle_explain(channel, topic):
    """Penjelasan ultra-pendek. AI-safe mode."""
    prompt = (
        f"Explain '{topic}' in 1-2 very short sentences. "
        f"No fluff. Simple. Direct. Max 180 tokens."
    )
    await channel.send(f"üìò Explaining **{topic}** (safe mode)...")
    txt, err = await call_gemini_safe(prompt) 
    if not txt or err:
        txt = f"‚ÑπÔ∏è (Fallback Mode) '{topic}' is a concept related to crypto/web3. No AI available."
    embed = discord.Embed(
        title=f"Explain: {topic}",
        description=truncate(txt, 600),
        color=0x66CCFF
    )
    embed.set_footer(text="SAFE-F Mode ‚Äî Minimal AI")
    await channel.send(embed=embed)

# ------------------------
# Main message router
# ------------------------
@client.event
async def on_message(message):
    if message.author == client.user:
        return
    content = message.content.strip()
    if not content.startswith("!"):
        return

    uid = message.author.id
    parts = content.split()
    cmd = parts[0]
    args = parts[1:]
    
    logger.info(f"{message.author} used {cmd}")

    if cmd in COMMANDS_WITH_COOLDOWN:
        if within_cooldown(uid):
            await message.channel.send(f"‚è≥ Wait {COOLDOWN_SECONDS}s.")
            return
        set_cooldown(uid)

    try:
        if content == "!help":
            await handle_help(message.channel); return
        if content == "!ping":
            latency_ms = round(client.latency * 1000) if getattr(client, 'latency', None) else 'N/A'
            await message.channel.send(f"pong ‚Äî {latency_ms} ms"); return

        if cmd == "!whatis":
            if not args:
                await message.channel.send("‚ö†Ô∏è Usage: `!whatis <term>`"); return
            term = " ".join(args)
            await handle_whatis(message.channel, message.author, term); return
            
        if cmd == "!explain":
            if not args:
                await message.channel.send("‚ö†Ô∏è Usage: `!explain <topic>`")
                return
            topic = " ".join(args)
            await handle_explain(message.channel, topic); return

        if cmd == "!analyze":
            if not args:
                await message.channel.send("‚ö†Ô∏è Usage: `!analyze <text to analyze>`"); return
            text = " ".join(args)
            await handle_analyze(message.channel, message.author, text); return

        if cmd == "!risk":
            if not args:
                await message.channel.send("‚ö†Ô∏è Usage: `!risk <text to analyze>`"); return
            text = " ".join(args)
            await handle_risk(message.channel, message.author, text); return

        if cmd == "!compare":
            await message.channel.send("üöß `!compare` is currently under development (MCP Integration Roadmap).")
            return

        if cmd == "!trend":
            if not args:
                await message.channel.send("‚ö†Ô∏è Usage: `!trend <keyword>`"); return
            keyword = " ".join(args)
            await handle_trend(message.channel, keyword); return

        if cmd == "!hunt":
            if not args:
                await message.channel.send("‚ö†Ô∏è Usage: `!hunt <keyword>`"); return
            short_mode = "--short" in content or "-s" in content
            temp = content.replace("--short", "").replace("-s", "")
            keyword = temp.split(" ", 1)[1].strip()
            await handle_hunt(message.channel, message.author, keyword, short_mode); return

        if cmd == "!context":
            if not args:
                await message.channel.send("‚ö†Ô∏è Usage: `!context <topic>`")
                return
            topic = " ".join(args)
            await handle_context(message.channel, message.author, topic); return
            
        if cmd == "!graph":
            if not args:
                await message.channel.send("‚ö†Ô∏è Usage: `!graph <keyword>`"); return
            keyword = " ".join(args)
            await handle_graph(message.channel, message.author, keyword); return

    except Exception as e:
        logger.exception(f"An error occurred in on_message: {e}")
        await message.channel.send(f"‚ö†Ô∏è An unexpected error occurred. Please tell the admin: `{e}`")

# ------------------------
# Run
# ------------------------
async def _shutdown():
    logger.info("Shutting down: closing HTTP session...")
    await safe_http.close()

if not DISCORD_TOKEN or not MEMBIT_KEY:
    logger.error("Missing env variables. Set DISCORD_TOKEN and MEMBIT_API_KEY in .env (GEMINI optional).")
else:
    if GEMINI_KEY and not model:
        logger.warning("Gemini key provided but model failed to initialize ‚Äî AI features disabled.")
    try:
        client.run(DISCORD_TOKEN)
    finally:
        try:
            loop = asyncio.get_event_loop()
            if loop.is_running():
                loop.create_task(_shutdown())
            else:
                loop.run_until_complete(_shutdown())
        except Exception:
            pass
